---
title: "Early Detection of Coronary Heart Disease Risk Using Supervised Machine Learning: 
         A Predictive Model Selection Approach"
author: "Yared Abraha"
date: "2025-02-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Final Project Machine Learning Model Development Workflow
```{r}
# Final Project Machine Learning Model Development Workflow
# Data set used: Framingham Heart Study Data set 
# --Load the Framingham heart study data set into R
# Step 1: Exploratory Data Analysis (EDA)
# -- EDA help understand the data structure, issues in the data, and distributions 
# 1.1 Explore the data set and data types 
# --Perform data/features metadata operation to make the data suitable for further analysis
# 1.2 Explore Issues in the Data 
# -Check for duplicates 
# -Check for missing values 
# -Check for distribution of the target variable
# -Check for outliers(extreme values) 
# 1.3 Data Analysis 
# -Descriptive Statistics (summary statistics of features)
# -Univariate Analysis (distribution of features) 
# -Bivariate Analysis (relationship between features and target)
# -Multivariate Analysis (relationship between multiple features)
# Step 2: Splitting the data set and Data Preparation for Modeling 
# 2.1 Split the data set (training/validation/testing)
# 2.2 Data Cleaning (Handling missing values)
# 2.3 Data Pre-processing 
# -Handling outliers
# -Feature selection
# -Handling target imbalance
# Step 3: Model Development 
# Random Forest, Logistic Regression, Support Vector Machine (SVM)
# -Train model using training Set
# -Evaluate model using validation Set
# -Cross Validation + Hyperparameter tuning 
# -Retrain model using best Hyperparameters found 
# -Evaluate model again using validation set
# Step 4: Final Model Evaluation
# -Final model evaluation using testing set (unseen data)
# -Compare models and select the best model using appropriate metrics

```

# Load Libraries and Framingham data set
```{r}
# Libraries for clean Exploratory Data Analysis (EDA)
# Using tidyverse and ggplot2 for clean data analysis
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tibble)

```



```{r}
# Load the Framingham data set into R using tidyverse readr 
framingham_original <- readr::read_csv("data/framingham_data.csv", show_col_types = FALSE)  

# keep the copy of the original data set to use it later (if needed) 
framing_data1 <- framingham_original

```

# Step1: Exploratory Data Analysis (EDA)
# 1.1 Explore the data set and data types
```{r}
## Step1: Exploratory Data Analysis (EDA)
# --Understand the Data structure of the Framingham heart study data set 
# 1.1 Explore the data set and data types
# Display the first fifteen rows of the data set 
head(framingham_original, n = 15)
# Display the full data set on a new window
View(framingham_original)

```

```{r}
# Explore number of rows and columns of the data set
cat("Total Rows:", nrow(framingham_original), "|Features(Predictors):", ncol(framingham_original) -1, 
    "|Target Variable(Predicted):", names(framingham_original)[ncol(framingham_original)], "\n")
# Column names of the data set 
names(framingham_original)
```
```{r}
# Summary statistics to explore correctness and spot issues
summary(framingham_original)
```
# Explore the data types
```{r}
# Check the data types of features (predictors) and target (predicted) 
glimpse(framingham_original)

```
```{r}
# Data/features metadata operation to make the data suitable for further analysis
# Change column names into appropriate, short, and easy to display names
# Use the copied data to keep the original safe (untouched)
framing_data1 <- framing_data1 %>% # using pip operator to chain operations and automate change of column name 
  rename(
    gender = male, # male is inappropriate (change it to gender)
    stroke = prevalentStroke, # stroke is shorter and explanatory
    hypertension = prevalentHyp, # hypertension is short and explanatory
    CHDRisk = TenYearCHD # the aim of the project is to detect CHD risk earlier
  )
# Display the updated column names 
names(framing_data1)  

```

```{r}
# Identify which features are numeric and which are categorical  
# Using Pip operator to chain operations and determine number of unique values of the features
framing_data1 %>%
  summarise(across(everything(), ~ n_distinct(.))) %>% # count number of unique values across rows
  pivot_longer(everything(), names_to = "Features", # display column name 1 and list of features
               values_to = "Number_Of_Unique_Values") %>%  # display column name 2 and number of unique values
  arrange(Number_Of_Unique_Values)

```

```{r}
# Determine between numeric and categorical features 
framing_data1 %>% # pip operator to chain functions 
  summarise(across(everything(), ~ n_distinct(.))) %>% # count unique values
  pivot_longer(everything(), names_to = "Features", # dispaly all features
               values_to = "Number_Of_Unique_Values") %>%  # count of unique values
         mutate(
           Variable_Type = ifelse(Number_Of_Unique_Values <= 5, "Categorical", # from previous analysis we know 5 is max 
           "Numeric")
           )%>%
  arrange(Variable_Type, Number_Of_Unique_Values)

```

# Change categorical features into Factor
```{r}
# Change categorical features into Factor for accurate analysis and interpretation 
# Prepare features for proper plotting and modeling
framing_factored <- framing_data1 %>% # keep the updated data set on new variable framing_factored
  mutate(across(where(~ n_distinct(.) <= 5), as.factor)) # change variables with 5 or less unique values into factor
str(framing_factored)

```

# 1.3 Explore issues in the data
```{r}
# 1.3 Explore issues in the data
# Check for duplicates 
any(duplicated(framing_factored))

```
# Check for Missing Values
```{r}
# Check for number and proportion of missing value in each column(feature)
# Using tibble object enframe for a clean output 
missing_per_feature <- enframe(colSums(is.na(framing_factored)),
                           name = "Feature",
                           value = "Number_of_Missing_Values")  %>% 
  mutate(Percentage_Per_Column = paste0(round((Number_of_Missing_Values / nrow(framing_factored)) * 100, 1), "%")) 
 print(missing_per_feature)

# Calculate percentage(proportion) of missing value per row
missing_row_proportion <- paste0(round(rowMeans(is.na(framing_factored))  * 100, 1), "%")
# Create a summary table of how many times each row proportion appears 
missing_per_row <- table(missing_row_proportion) %>% 
  as.data.frame() %>% # display it as a data frame
  rename(Missing_Row_Percentage = missing_row_proportion, Total_Number = Freq) %>% # frequency count gives total number  
  mutate(Percentage_of_Total_Rows = paste0(round((Total_Number / nrow(framing_factored)) * 100, 1), "%"))

print(missing_per_row)
# LOATS OF MISSING VALUES ARE FOUND!(Needs to be handled later on!)
```

# Check for distribution of the Target Variable(CHDRisk)
```{r}
# Check the distribution of the Target Variable
# To measure if there exist a class imbalance 
framing_factored %>% 
  count(CHDRisk) %>%
  mutate(Percentage = paste0(round(n/sum(n) * 100), "%")) 

```


```{r}
# Barplot showing the distribution of target variable CHDRisk
framing_factored %>% 
  count(CHDRisk) %>% # count number of 0s and 1s
  mutate(Percent = paste0(round(n/sum(n) * 100, 1)), # mutate calculate percentage of distribution
         CHDRisk = factor(CHDRisk, levels = c(0,1), labels = c("NoRisk", "HighRisk"))) %>% # change 0,1 labels to words
  ggplot(aes(x = CHDRisk, y = n, fill = CHDRisk)) + # ggplot assign x and y values and a legend (CHDRisk)
  geom_col(width = 0.5) + 
  geom_text(aes(label = paste0(n, " (", Percent, "%)")), vjust = -0.2, size = 3.5) + # display percentage on bars
  scale_fill_manual(values = c("skyblue", "brown"))+ # adjust color of the bars
  labs(title = "Distribution of Target Variable (CHDRisk)", x = "CHDRisk", y = "Count") +
  theme_minimal() # clean background for clear display

# THERE IS AHUGE CLASS IMBALANCE FOUND 0(NoRisk = 84.8%) and 1(HighRisk = 15.2%)
```
# Check for outliers(extreme values)
```{r}
# Check for outliers in the numeric features using a box plot
framing_factored %>% # explore through the whole data set
  select(where(is.numeric)) %>% # select only numeric features
  pivot_longer(everything()) %>% # include all data points and keep them in a long format
  ggplot(aes(x = "", y = value)) + # assign value for y-axis, and nothing for x-axis
  geom_boxplot(fill = "skyblue") + # the box plot color is set to be sKyblue
  facet_wrap(~name, scales = "free") + # produce a grid display where all features and their outliers are displayed 
  theme_minimal() # clear background
# THERE ARE A LOT OF OUTLIERS IN ALL NUMERIC FEATURES EXCEPT AGE!
# NEEDS TO BE HANDLED LATER ON!

```
```{r}
# IQR method to compute outlier thresholds (computed for each features, glucose is considered here)
first_quartile <- quantile(framing_factored$glucose, 0.25, na.rm = TRUE) # the median of the lower half of the data
third_quartile <- quantile(framing_factored$glucose, 0.75, na.rm = TRUE) # the median of the upper half of the data
interquartile_range <- third_quartile - first_quartile # measure the mid spread of the data
# calculate lower and upper thresholds
lower_threshold <- first_quartile - 1.5 * interquartile_range # any value smaller than this is an outlier
upper_threshold <- third_quartile + 1.5 * interquartile_range # any value greater than this is an outlier

# Draw box plot to visually see the outliers 
# Detecting outliers in glucose
ggplot(framing_factored, aes(x = "", y = glucose)) + # extract glucose and count of glucose represent the y axis
  geom_boxplot(fill = "skyblue") + # the box plot is filled skyblue color
  geom_hline(yintercept = lower_threshold, linetype = "dashed", color = "red") + # draw the lower threshold 
  geom_hline(yintercept = upper_threshold, linetype = "dashed", color = "red") + # draw the upper threshold 
  labs(title = "Boxpot with red dashed outlier threshold to detect outliers in glucose") +
  theme_minimal()

```

```{r}
# Calculate number and percentage of outliers in the numeric features 
framing_factored %>%
  select(where(is.numeric)) %>% # select only numeric features
  # select all columns and summarise to rows
  summarise(across(everything(), ~{    # (~/tidle in R) operator introduce function to be applied on each feature
    first_q <- quantile(.x, 0.25, na.rm = TRUE) # na.rm = TRUE ignores the NA (misisng) values 
    third_q <- quantile(.x, 0.75, na.rm = TRUE)
    interquartile_r <- third_q - first_q # calculate interquartile range
    lower_thr <- first_q - 1.5 * interquartile_r
    upper_thr <- third_q + 1.5 * interquartile_r
    # for each feature (.x) count values that are less than the lower bound and or greater than the upper bound
    sum(.x < lower_thr | .x > upper_thr, na.rm = TRUE) # .x represent current value (feature) explored
  })) %>%
  pivot_longer(everything(), names_to = "Features", # converts to longer format and output column name
               values_to = "Number_Of_Outliers") %>% # output column name
  mutate(Percentage = round(Number_Of_Outliers / nrow(framing_factored), 3)) # percentage of outliers per feature

```

# 1.3 Data Analysis 
```{r}
# 1.3 Data Analysis 
# Descriptive Statistics (summary statistics of features)
# See the statistical difference of changing categorical variables into factors
summary(framing_factored)

```
# -Univariate Analysis (distribution of features)
```{r}
# -Univariate Analysis  
# Histogram is used to show distribution of all numeric feature 
framing_factored %>%
  select(where(is.numeric)) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value)) +
  geom_histogram(bins = 30, fill = "skyblue", colour = "black") + # historgram
  facet_wrap(~name, scales = "free", ncol = 3) +
  labs(title = "Histogram showing distribution of all numeric features", x ="Value", y = "Count") +
  theme_minimal()

```
```{r}
# Histogram for each feature ( e.g, sysBP)
ggplot(framing_factored, aes(x = sysBP)) +
  geom_histogram(bins = 50, fill = "skyblue", colour = "black") +
  labs(title = "Histogram showing the distribution of sysBP", x = "Systolic Blood Pressure", y = "Count") +
  theme_minimal()

```

```{r}
# Barplot showing distribution of all categorical features
framing_factored %>%
  select(where(is.factor)) %>%
  pivot_longer(everything(), names_to = "Feature", values_to = "Value") %>%
  ggplot(aes(x = Value, fill = Value)) +
  geom_bar() +
  geom_text(stat = "Count", aes(label = ..count..),position = position_stack(vjust = 1.1), size = 2.5) + # add count on bar
  facet_wrap(~ Feature, scales = "free") +
  scale_fill_manual(values = c("skyblue", "red", "green", "yellow","purple", "grey"))+  # manually fill color
  labs(title = "Barplot showing distribution of categorical features", x = "Categorical Features", y = "Count") +
  theme(strip.text = element_text(margin = ggplot2::margin(b = 10))) +
  theme_minimal()

```

```{r}
# Barplot showing distribution of each categorical features (e.g, gender) 
framing_factored %>%
  count(gender) %>%
  ggplot(aes(x = gender, y = n, fill = gender)) + # x = gender level (0, 1), y = count value, fill = legend
  geom_bar(stat = "identity", width = 0.5) + # size of bar
  geom_text(aes(label = n), vjust = -0.3, size = 3) + # adjust the display of count on top of bar
  scale_fill_manual(values = c("skyblue", "red")) +
  labs(title = "Distribution of Gender", x = "Gender Status", y = "Count") +
  theme_minimal() 

```
# Bivariate Analysis (relationship between features and target)
```{r}
# Bivariate Analysis showing the relationship between numeric features and target 
framing_factored %>%
  select(where(is.numeric), CHDRisk) %>% # features distribution in CHDRisk labels (0, 1)
  pivot_longer(-CHDRisk, names_to = "Feature", values_to = "Value") %>%
  ggplot(aes(x = CHDRisk, y = Value, fill = CHDRisk)) +
  geom_boxplot() +
  facet_wrap(~ Feature, scales = "free", ncol = 3) +
  labs(title = "Realtionship between numeric features and target", x = "CHDRisk(Target)", y = "Level") +
  scale_fill_manual(values = c("skyblue", "red")) +
  theme_minimal()

```
```{r}
# Individual feature vs target (e.g, glucose vs CHDRisk)
ggplot(framing_factored, aes(x = CHDRisk, y = glucose, fill = CHDRisk)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red", outlier.size = 1.5) + # showing red colored outlier points 
  theme(plot.title = element_text(face = "bold", size = 14)) +
  labs(title = "Glucose distribution by CHDRisk status", x = "CHDRisk(Target)", y = "Glucose Level") +
  scale_fill_manual(values = c("skyblue", "red")) + # color CHDRisk levels
  theme_minimal()

```
```{r}
# Bivariate analysis (proportional bar plot)
# Showing relationship between categorical features vs target
framing_factored %>%
  select(where(is.factor), CHDRisk) %>%
  pivot_longer(-CHDRisk, names_to = "Feature", values_to = "Value" ) %>%
  group_by(Feature, Value, CHDRisk) %>% # feature proportion in respect to CHDRisk levels
  summarise(n = n(), .groups = "drop") %>%
  group_by(Feature, Value) %>%
  mutate(Proportion = n/sum(n)) %>%
  
  ggplot(aes(x = Value, y = Proportion, fill = CHDRisk)) + # y sh0woing percentage proportion
  geom_col(position = "fill") + # proportional column showing percentage of CHDRisk
  #geom_bar(stat = "identity", position = "fill") +
  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), position = position_fill(vjust = 0.5), size = 3,
            color = "black") +
  facet_wrap(~ Feature, scales = "free_x") + # display them in one large grid
  scale_y_continuous(labels = scales::percent) + # make y-axis scale percentage
  scale_fill_manual(values = c("skyblue", "red"))+
  labs(labs(title = "Proportional Bar Plot of categorical features vs target", x = "Feature Levels", y = "Proportion")) +
  theme_minimal()

```

```{r}
# Proportional bar plot for individual features vs target
# e.g glucose vs target(CHRisk))
framing_factored %>%
  count(diabetes, CHDRisk) %>%
  group_by(diabetes) %>% # diabetes feature is used
  mutate(percent = n/sum(n) * 100) %>% # calculate percentage 
  ggplot(aes(x = diabetes, y = percent, fill = CHDRisk)) + # plot diabetes in respect to CHDRisk
  geom_col(position = "fill", width = 0.5) + # adjust bar size
  geom_text(aes(label = paste0(round(percent, 0), "%")), # add percentage in the middle of the bar
            position = position_fill(vjust = 0.5), 
            color = "black", size = 3) +
  scale_y_continuous(labels = scales::percent) +  # y-axis represent percentage
  scale_fill_manual(values = c("skyblue", "red")) + 
  labs(title = "Proportional Bar Plot: Diabetes vs CHDRisk", 
       x = "CHDRisk Status", y = "Proportion", fill = "CHDRisk") +
  theme_minimal() 

```

# Multivariate Analysis 
```{r}
# Multivariate Analysis shows the relationship between multiple features
# Helps to detects multicollinearity between variables 
# Correlation matrix heatmap to show relationship between numeric features
# Calculate correlation between multiple numeric features 
correlation_matrix <- cor(framing_factored[sapply(framing_factored, is.numeric)], use = "complete.obs")

# create a dataframe to store the calculated correlation
correlation_dataFrame <- as.data.frame(as.table(correlation_matrix))
colnames(correlation_dataFrame) <- c("Vars1", "Vars2", "Correlation") # assign column names for correlation output
#print(correlation_dataFrame)
# Visualise using ggplot
ggplot(correlation_dataFrame, aes(Vars1, Vars2, fill = Correlation)) + 
  geom_tile(color = "white") +
  geom_text(aes(label = round(Correlation, 1)), size = 3.5, color = "black") + # fill correlation values inside the grid
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",
                       midpoint = 0,limit = c(-1, 1),space = "Lab",name = "Correlation") + # assign grid color and correl range
  labs(title = "Correlation Matrix Heatmap:Relatinship between numeric features",
       x = "Numeric Features", y = "Numeric Features") +
  theme_minimal() 
  
```

```{r}
# Scatter plot to check multicollinearity between numeric features (sysBP vs diaBP)
# Compute correlation 
correl_value <- cor(framing_factored$sysBP, framing_factored$diaBP, use = "complete.obs")
# Plot the scatter plot 
framing_factored %>% 
  ggplot(aes(x = sysBP, y = diaBP, color = CHDRisk)) + # colored with CHDRisk
  geom_point()+ # draw scatter points 
  scale_color_manual(values = c("0" = "skyblue", "1" = "red")) +
  geom_smooth(method = "lm", se = FALSE) + # draw the line of best fit (straght line)
  labs(title = "Scatterplot showing relationship between sysBP and diaBP (colored with CHDRisk)",
       x = "Systolic Blood Pressure", y = "Diastolic Blood Pressure") +
  annotate("text", x = 110, y = 110, label = paste("Correlation =", round(correl_value, 1)), size = 4) + # add correl value
  theme_minimal()


```

```{r}
# Measure of multicollinearity (Variance Inflation Factor (VIF)
# function to calculate VIF across all numeric features
variance_inflation_factor <- function(dataset) { # function takes the framing factored data
  numeric_features <- dataset %>% select (where(is.numeric)) # select numeric features from the data set passed
  vif_values <- map_dfr(names(numeric_features),function(var) {
    lm_calculation <- as.formula(paste(var, "~."))
    r_squared <- summary(lm(lm_calculation, data = numeric_features))$r.squared # obtain r squared value from the regression
    VIF_calculation <- 1 / (1 - r_squared) # calculate VIF
    tibble(Features = var, Variance_Inflation_Factor = round(VIF_calculation, 2)) # create tibble and display output
    })
  vif_values
}

# call function by passing framing factored dataset 
vif_values <- variance_inflation_factor(framing_factored)
print(vif_values)

```


```{r}
# Cramer's V to measure relationship between categorical features
# Similar to correlation matrix for numeric features
# Select categorical features from the data set 
categorical_features <- framing_factored %>%
  select(where(is.factor), -CHDRisk)
# Extract names of categorical features
feature_names <- names(categorical_features)
# Function to calculate Cramer's V between two categorical features 
crm_value <- function(a,b) {
  contingency_table <- table(a,b) # contingency table for chi square test
  chi2_test <- chisq.test(contingency_table, correct = FALSE)$statistic # chi square values calculated
  tot_observation <- sum(contingency_table) # number of data points 
  phi_squared <- chi2_test / tot_observation # phi squared calculated
  smaller <- min(nrow(contingency_table), ncol(contingency_table)) # extract smaller count across rows and column from ct
  sqrt(as.numeric(phi_squared)/ (smaller -1)) # Cramer's V calculated
}
# Create a matrix to store the calculated Cramer's V 
cr_matrix <- matrix(NA, nrow = length(feature_names), ncol = length(feature_names),
                    dimnames = list(feature_names, feature_names))
# Use for loop to fill the matrix going through the features
for(x in seq_along(feature_names)) {
  for(y in seq_along(feature_names)){
    cr_matrix[x,y] <- crm_value(categorical_features[[x]],
                                categorical_features[[y]]) # matrix is filled here
  }
}
# convert to df for clean output
CV_df <- as.data.frame(round(cr_matrix,2))
# print the data frame
print(CV_df)

```


```{r}
# Heatmap for Cramer's V matrix (categorical features relationship
# Convert matrix to long format for ggplot2
long_matrix <- as.data.frame(as.table(cr_matrix)) %>%
  rename(Var1 = Var1, Var2 = Var2, V = Freq) %>%
  drop_na()
# Plot the heatmap matrix
ggplot(long_matrix, aes(x = Var1, y = Var2, fill = V)) + # Cramer's V value filled in the relationship grid
  geom_tile(color = "white") +
  geom_text(aes(label = round(V, 2)), size = 3.5) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.3, # manually color grid
                       limit = c(0,1),  name = "Cramer's V") + # with legend on the right
  labs(title = "Cramer's V Heatmap:Categorical Features Relationship", 
       x = "Categorical Features", y = " Categorical Features") +
  theme_minimal()

```

# Step 2: Splitting the data set and data preparation for modeling
```{r}
# Library for sampling
library(rsample) 
```


```{r}
# 2.1 Splitting the data set 
# Proportion: training set 70% /validation set 15%/ testing set 15%
# Step 1: initial split 70% training 30% (validation + testing set)
# Use stratified sampling to balance the target (CHDRisk) distribution across sets
# Dealing with difficult imbalanced data
set.seed(123)
first_split <- initial_split(framing_factored, prop = 0.7, strata = CHDRisk)
train_framing <- training(first_split)
valid_and_test <- testing(first_split)

# Step 2: from valid_and_test, split 15% validation set, 15% testing set
second_split <- initial_split(valid_and_test, prop = 0.5, strata = CHDRisk)
valid_framing <- training(second_split)
test_framing <- testing(second_split)

# Check the split data sizes 
cat("Training Set:", nrow(train_framing), "\nValidation Set:", nrow(valid_framing), "\nTesting Set:", nrow(test_framing), "\n")
# Compare: original data size should be equal to the sum of the splits (training + validation + testing) 
nrow(framing_factored)
# Check distribution and size: target (CHDRisk) should be proportional for all sets)
table(train_framing$CHDRisk) / nrow(train_framing)
table(valid_framing$CHDRisk) / nrow(valid_framing)
table(test_framing$CHDRisk) / nrow(test_framing)

```
# 2.2 Data Cleaning 
# Hnadling missing values
# Identify missingness mechanism
```{r}
# Library for map function to determine missing mechanism
library(purrr) 

```



```{r}
# 2.2 Data Cleaning 
# Handling Missing Values (training set)
# First identify mechanisms of missing data in numeric features using Logistic Regression
# Check for Missing Completely At Random (MCAR), 
# Missing At Random (MAR) 
# Missing Not At Random (MNAR) 
# Numeric features with missing values
numeric_f_missing <- train_framing %>% select(where(is.numeric)) %>% # select numeric features
  select(where(~ any(is.na(.)))) %>% names() # numeric features with missing (NA) values
# Predictors: numeric features with no missing 
numeric_f_complete <- train_data1 %>% select(where(is.numeric)) %>% select(where( ~ all(!is.na(.))))
# Logistic regression to determine missing mechanism
numeric_missing_values <- map_df(numeric_f_missing, function (y){ # return numeric missing values and missing mechanism
  data_f <- data.frame(Missing = is.na(train_framing[[y]]), # create data frame for the model
                   numeric_f_complete)
  if (length(unique(data_f$Missing)) < 2) return(NULL)
  glm_mod <- glm(Missing ~., data = data_f, family = "binomial") # logistic regression model
  p_val_f <- summary(glm_mod)$coefficients [-1, 4] # extract the p_values from the model
  # Create a tibble for output
  tibble(
   Features = y, # y is numeric features with mising (NA) values
   Predictors = names(p_val_f), # all predictors for each feature
   P_values = round(p_val_f, 3),
   Missing_Mechanism = ifelse(min(p_val_f, na.rm = TRUE) > 0.05, "MCAR", "MAR") # Pp_val > 0.05(MCAR), < 0.05(MAR)
 )
} )
# print features and their identified missing mechanism 
print(numeric_missing_values)
# Note: output shows all features shows MCAR, except BMI(which is MAR)

```

```{r}
# Chi-squared test to diagnose MCAR/MAR in categorical features
# Extract categorical features (column)
categorical_f <- train_framing %>% select(where(is.factor)) %>% select(-CHDRisk)
# Feature with missing value 
f_withNA <- categorical_f %>% select(where(~ any(is.na(.))))
# Features without missing values
f_noNA <- categorical_f %>% select(where(~ all(!is.na(.))))
# chi-squared test result 
map_dfr(names(f_withNA), function(var){
  missing_f  <- is.na(f_withNA[[var]])
  
  map_dfr(names(f_noNA), function(predictor) {
    table_m <- table(missing_f, f_noNA[[predictor]])
    test_chisqr <- tryCatch(chisq.test(table_m), error = function(e) NULL) # calculate chi2-square 
    # Tibble for clean output 
    tibble(
      Features = var,
      Predictors = predictor,
      P_value = round(test_chisqr$p.value, 3), # round to 3decimal places
      Missing_Mechanism = ifelse(is.null(test_chisqr), NA,
                                ifelse(test_chisqr$p.value > 0.05, "MCAR", "MAR")) # p_val > 0.05(MCAR), < 0.05(MAR)
    )
  })
})
# Note: output shows all categorical features have MCAR missing mechanism

```

# Now missing mechanism is known (Next Imputation)
# Calculate imputation value only using the training data 
# Impute validation and testing set using calculated value using training set (avoids DATA LEAKAGE)
```{r}
# Handling the missing values (using IMPUTATION)
# Numeric features with MCAR missing mechanism (totChol, heartRate, glucose, cigsPerDay)
# Impute using MEDIAN (robust against outliers)
# Calculate median only using the training data and impute validation and testing set using median(avoids DATA LEAKAGE)
# Copy and keep the original training data 
train_Fimputed <- train_framing

# Calculate median for each numeric feature 
median_totChol1 <- median(train_framing$totChol, na.rm = TRUE) # ignore NA values
median_heartRate1 <- median(train_framing$heartRate, na.rm = TRUE)
median_glucose1 <- median(train_framing$glucose, na.rm = TRUE)

# CigsPerDay should be computed for currentSmokers only
median_cigsPerDay1 <- train_framing %>%
  filter(currentSmoker == 1, !is.na(cigsPerDay)) %>% # only current smokers smoke cigarette 
  summarise(median_cigarette = median(cigsPerDay)) %>% # compute the median
  pull(median_cigarette) # extract median value

# Impute missing values (NA) in each feature in the training set using mutate from tidyverse package
train_Fimputed <- train_Fimputed %>%
  mutate(
    cigsPerDay = ifelse(is.na(cigsPerDay), median_cigsPerDay1, cigsPerDay),
    totChol = ifelse(is.na(totChol), median_totChol1, totChol),
    heartRate = ifelse(is.na(heartRate), median_heartRate1, heartRate),
    glucose = ifelse(is.na(glucose), median_glucose1, glucose)
  )
# print the medians to investigate
print(median_cigsPerDay1)
print(median_totChol1)
print(median_heartRate1)
print(median_glucose1)

```

```{r}
# Numeric feature with MAR missing mechanism is BMI 
# Impute using K-Nearest Neighbor (KNN) median imputation for MAR mechanism
# Assign the target missing MAR feature 
feature_MAR <- "BMI"
# Select numeric features (predictors) with no missing values
features_noNA <- train_framing %>%
  select(where(is.numeric), -all_of(feature_MAR)) %>% # select all numeric except BMI
  select(where(~ !any(is.na(.)))) %>% # select all features with no missing values
  names()
# scale features to use as predictors in KNN 
scaled_F <- train_Fimputed %>%
  mutate(across(all_of(features_noNA), scale)) 

# calculate one KNN based median imputation value 
knn_median_value1 <- scaled_F %>% # used the scaled value
  filter(!is.na(.data[[feature_MAR]])) %>% # filter features with no mising values
  mutate(dist_to_missing = rowSums((select(.,all_of(features_noNA))- colMeans(scaled_F[is.na(scaled_F[[feature_MAR]]),features_noNA], na.rm = TRUE))^2)) %>% # calculate distance (knn)
  arrange(dist_to_missing) %>% # distance calculated is arranged 
  slice_head() %>%
  pull({{feature_MAR}}) %>% # extract BMI 
  median(na.rm = TRUE) %>% # median ignoring NA
  as.numeric()

# Impute BMI missing value(NAs) in the training set using the KNN median computed
train_Fimputed <- train_Fimputed %>%
  mutate(
    BMI = ifelse(is.na(BMI), knn_median_value1, BMI))

# print to check results
print(features_noNA)
print(knn_median_value1)
str(train_Fimputed)

```


```{r}
# Impute categorical features (education and BPMeds) with MCAR mechanism
# MCAR missing mechanism, using mode imputation
# Compute mode for the two features
mode_education1 <- as.numeric(names(which.max(table(train_Fimputed$education, useNA = "no"))))
mode_BPMeds1 <- as.numeric(names(which.max(table(train_Fimputed$BPMeds, useNA = "no"))))

# Impute missing values(NAs) in the training set with the mode
train_Fimputed <- train_Fimputed %>%
  mutate(
    education = case_when(is.na(education) ~ factor(mode_education1, levels = levels(education)),
                          TRUE ~ education),
    BPMeds = case_when(is.na(BPMeds) ~ factor(mode_BPMeds1, levels = levels(BPMeds)),
                       TRUE ~ BPMeds)
  )

print(mode_education1)
print(mode_BPMeds1)

```

```{r}
# Check the imputation done on the training set
# Display features, missing values count, and data type
imputed_train1 <- train_Fimputed %>% # function aplied on the training data set 
  summarise(across(everything(), ~ sum(is.na(.)))) %>% # add all missing values (if any) 
  pivot_longer(everything(), names_to = "Feature", values_to = "Missing_Count") %>% # output columns assigned with longer
  mutate(Data_Type = sapply(train_Fimputed[, Feature], class)) # mutate to assign data type values for each feature

# print imputation result (there should be 0 missing value in the training set)
print(imputed_train1)

```

# Impute validation and testing set
```{r}
# Now clean(handle missing values)in the validation and testing set 
# Using the medians, KNN median, and mode calculated using the training set to avoid data leakage
# Impute the validation set 
valid_Fimputed <- valid_framing # keep a copy of the original validation set
# Just impute using values from the training imputation
# mutate to change NAs with calculated median/mode in each features with missing values
valid_Fimputed <- valid_Fimputed %>%
  mutate(
    cigsPerDay = ifelse(is.na(cigsPerDay), median_cigsPerDay1, cigsPerDay),
    totChol = ifelse(is.na(totChol), median_totChol1, totChol),
    heartRate = ifelse(is.na(heartRate), median_heartRate1, heartRate),
    glucose = ifelse(is.na(glucose), median_glucose1, glucose),
    BMI = ifelse(is.na(BMI), knn_median_value1, BMI),
    education = case_when(is.na(education) ~ factor(mode_education1, levels = levels(education)),
                          TRUE ~ education),
    BPMeds = case_when(is.na(BPMeds) ~ factor(mode_BPMeds1, levels = levels(BPMeds)),
                       TRUE ~ BPMeds)
  )

# Impute the testing set
test_Fimputed <- test_framing # keep a copy of the original testing set
# Just impute using values from the training imputation
# mutate to change NAs with calculated median/mode in each features with missing values
test_Fimputed <- test_Fimputed %>%
  mutate(
    cigsPerDay = ifelse(is.na(cigsPerDay), median_cigsPerDay1, cigsPerDay),
    totChol = ifelse(is.na(totChol), median_totChol1, totChol),
    heartRate = ifelse(is.na(heartRate), median_heartRate1, heartRate),
    glucose = ifelse(is.na(glucose), median_glucose1, glucose),
    BMI = ifelse(is.na(BMI), knn_median_value1, BMI),
    education = case_when(is.na(education) ~ factor(mode_education1, levels = levels(education)),
                          TRUE ~ education),
    BPMeds = case_when(is.na(BPMeds) ~ factor(mode_BPMeds1, levels = levels(BPMeds)),
                       TRUE ~ BPMeds)
  )

```


```{r}
# Check the imputation done on the validation set
# Display features, missing values count, and data type
imputed_val1 <- valid_Fimputed %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  #filter(Missing_Count > 0) %>% # display features with missing values only
  mutate(Data_Type = sapply(train_imputed[, Variable], class))

# Ckeck imputation done on the test set
imputed_test1 <- test_Fimputed %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  #filter(Missing_Count > 0) %>% # display features with missing values only
  mutate(Data_Type = sapply(train_imputed[, Variable], class))

# Print imputed results to show missing values (all features should display 0 missing values)
print(imputed_val1)
print(imputed_test1)

```

# 2.3 Data Pre-processing 
# Handling Outliers
```{r}
# 2.3 Data Pre-processing 
# Handling Outliers (first see their distribution in the training set)
train_Fimputed %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = "", y = value)) +
  geom_boxplot(fill = "skyblue") +
  facet_wrap(~name, scales = "free") +
  theme_minimal()
# Note: the output show that there are still lots of outliers in the training set
```

```{r}
# IRQ Capping method is used to handle the outliers in numeric features
# Values above and below the capping threshold are capped with the upper/lower threshold value 
# upper threshold = first quartile - 1.5 * interquartile range
# lower threshold = third quartile + 1.5 * interquartile range
feature_names <- c("age", "cigsPerDay", "totChol", "sysBP", "diaBP", "BMI", "heartRate", "glucose") # numeric features
# create a data frame to store features and capping threshold (lower, upper)
capping_DF <- data.frame(feature = character(),
                            lower = numeric(), upper = numeric()) 
# keep copy of Fimputed data for safe pipeline                     
train_Fcapped <- train_Fimputed 
# For loop to go through the feature names vector and access each feature
for(feature in feature_names){
  f_quartile <- unname(quantile(train_Fimputed[[feature]], 0.25, na.rm = TRUE)) # calculate first quartile
  t_quartile <- unname(quantile(train_Fimputed[[feature]], 0.75, na.rm = TRUE)) # calculate third quartile
  i_quartile_r <- t_quartile - f_quartile # compute interqurtile range

lower_thr1 <- f_quartile - 1.5 * i_quartile_r # lower threshold 
upper_thr1 <- t_quartile + 1.5 * i_quartile_r # upper threshold
assign(paste0("cap_values_", feature), c(lower_thr1 = lower_thr1, upper_thr1 = upper_thr1)) # Assign threshold 

# Apply IQR Capping to the training data 
train_Fcapped[[feature]] <- pmin(pmax(train_Fcapped[[feature]], lower_thr1), upper_thr1)
# Add capping values for each feature to the capping table 
capping_DF <- rbind(capping_DF, data.frame(Feature = feature, Lower_Threshold = lower_thr1, Upper_Threshold = upper_thr1))
}
# Print the capping data frame to see capping threshold for each numeric feature
print(capping_DF)

```

```{r}
# Check to see if the capping method successfully handle the outliers
train_Fcapped %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = "", y = value)) +
  geom_boxplot(fill = "skyblue") +
  facet_wrap(~name, scales = "free") +
  theme_minimal()
# Note: output confirm all outliers are handled (no outlier in the training set)
```

```{r}
# Detecting outliers in glucose
ggplot(train_Fcapped, aes(x = "", y = glucose)) + # extract glucose and count of glucose represent the y axis
  geom_boxplot(fill = "skyblue") + # the box plot is filled skyblue color
  geom_hline(yintercept = lower_threshold, linetype = "dashed", color = "red") + # draw the lower threshold 
  geom_hline(yintercept = upper_threshold, linetype = "dashed", color = "red") + # draw the upper threshold 
  labs(title = "Boxpot with red dashed outlier threshold to detect outliers in glucose") +
  theme_minimal()

```


```{r}
# Calculate number and percentage of outliers in the numeric features 
train_Fcapped %>%
  select(where(is.numeric)) %>% # select only numeric features
  # select all columns and summarise to rows
  summarise(across(everything(), ~{    # (~/tidle in R) operator introduce function to be applied on each feature
    first_q <- quantile(.x, 0.25, na.rm = TRUE) # na.rm = TRUE ignores the NA (misisng) values 
    third_q <- quantile(.x, 0.75, na.rm = TRUE)
    interquartile_r <- third_q - first_q # calculate interquartile range
    lower_thr <- first_q - 1.5 * interquartile_r
    upper_thr <- third_q + 1.5 * interquartile_r
    # for each feature (.x) count values that are less than the lower bound and or greater than the upper bound
    sum(.x < lower_thr | .x > upper_thr, na.rm = TRUE) # .x represent current value (feature) explored
  })) %>%
  pivot_longer(everything(), names_to = "Features", # converts to longer format and output column name
               values_to = "Number_Of_Outliers") %>% # output column name
  mutate(Percentage = round(Number_Of_Outliers / nrow(framing_factored), 3)) # percentage of outliers per feature

```

```{r}
# Handle the outliers in validation and testing set (no recalculation of capping values)
# Using the cap values from the training set to avoid DATA LEAKAGE problem
# keep copy of the validation and testing set
valid_Fcapped <- valid_Fimputed
test_Fcapped <- test_Fimputed
feature_cols <- c("age", "cigsPerDay", "totChol", "sysBP", "diaBP", "BMI", "heartRate", "glucose")
for (feature in feature_cols) {
  cap_values2 <- get(paste0("cap_values_", feature)) # extract cap values from training cap
  
# update outliers in the validation set
  valid_Fcapped[[feature]] <- pmin(pmax(valid_Fcapped[[feature]], cap_values2["lower_thr1"]), 
                                  cap_values2["upper_thr1"])
  
# update outliers in the testing set 
  test_Fcapped[[feature]] <- pmin(pmax(test_Fcapped[[feature]], cap_values2["lower_thr1"]), 
                                  cap_values2["upper_thr1"])
  
  print(cap_values2) # print lower and upper capping values
}

```

# Feature Selection
```{r}
# Based on medical domain knowledge research education has less predictive power for CHD
# Statistical Cramer's v heat map matrix also show weak relationship and predictive power
# It is also mutivalued that could lead to bias and model complexity, therefore better dropped
# Drop it from train_Fcapped
train_Fcleaned <- train_Fcapped %>% select(-education)
# Drop it from valid_Fcapped
valid_Fcleaned <- valid_Fcapped %>% select(-education)
# Drop it from test_Fcapped
test_Fcleaned <- test_Fcapped %>% select(-education)

```


# Handling Target Imbalance
```{r}
# Handling target imbalance (important for modeling, especially for CHD prediction)
# Target imbalance cause prediction to be biased towards majority class 
# The framingham data is hugely imbalanced (85% majority class(0) for no CHD risk, 15% minority class(1) for CHD risk
# oversampling target balancing method ADASYN( Adaptive SMOTE) is used to create synthetic samples to increase minority
library(smotefamily) # to implement ADASYN
train_Fada <- train_Fcleaned # Copy to keep cleaned trained data safe
train_Fada <- train_Fada %>%
  mutate(across(where(is.factor), ~ as.numeric(as.character(.)))) # change all factor (categorical) features to numeric
train_Fada$CHDRisk <- as.factor(train_Fada$CHDRisk) # keep the target as factor
# Separate predictor features and target (CHDRisk)
x_predictors <- train_Fada %>% select(-CHDRisk)
y_target <- train_Fada$CHDRisk

# Apply ADASYN to create synthetic data to balance the target CHDRisk
ADASYN_synthetic <- ADAS(x_predictors, y_target, K = 4)
train_FADASYN <- ADASYN_synthetic$data

```


```{r}
# Check the generated synthetic data
View(train_FADASYN)
str(train_FADASYN)
```
```{r}
# ADASYN changed the target variable name into class, rename it back to CHDRisk
train_FADASYN <- train_FADASYN %>% rename(CHDRisk = class)
# Convert target (CHDRisk) back to factor
train_FADASYN$CHDRisk <- as.factor(train_FADASYN$CHDRisk)
# Check the new target distribution 
table(train_FADASYN$CHDRisk)
prop.table(table(train_FADASYN$CHDRisk))

```
```{r}
# graphical representation of target variable distribution
train_FADASYN %>% 
  count(CHDRisk) %>%
  mutate(Percent = paste0(round(n/sum(n) * 100, 2)),
         CHDRisk = factor(CHDRisk, levels = c(0,1), labels = c("NoRisk", "HighRisk"))) %>%
  ggplot(aes(x = CHDRisk, y = n, fill = CHDRisk)) +
  geom_col(width = 0.5) +
  geom_text(aes(label = paste0(n, " (", Percent, "%)")), vjust = -0.2, size = 3.5) +
  scale_fill_manual(values = c("skyblue", "brown"))+
  labs(title = "Distribution of Target Variable (CHDRisk)", x = "CHDRisk", y = "Count") +
  theme_minimal()
# Note: the barplot output showed a balanced distribution(50.04%/49.96%) of target(CHDRisk) (0 = NoRisk, 1 = HighRisk)
```
```{r}
# After ADASYN the structure of the data such as decimal places and data types are changed 
# Rearrange them back to their original structure (features have different structures)
# Round them to appropriate decimal points
# Categorical variables (binary, 0 and 1)
cat_F0dp <- c("gender", "currentSmoker", "BPMeds", "stroke", "hypertension", "diabetes")
train_FADASYN[cat_F0dp] <- lapply(train_FADASYN[cat_F0dp], round)
# Whole numbers (integers)
integer_F <- c("age", "cigsPerDay", "heartRate")
train_FADASYN[integer_F] <- lapply(train_FADASYN[integer_F], round)
# Round to 1 decimal place(dp1)
dp1_F <- c("diaBP", "glucose", "totChol")
train_FADASYN[dp1_F] <- lapply(train_FADASYN[dp1_F], round, digits = 1)
# Round to 2 decimal place (2dp)
dp2_F <- c("sysBP", "BMI")
train_FADASYN[dp2_F] <- lapply(train_FADASYN[dp2_F], round, digits = 2)
```

```{r}
# Check the rearranged data structure
str(train_FADASYN)
View(train_FADASYN)
```
# Step 3: Model Development 
# Balanced Random Forest (BRF)
```{r}
# Libraries for BRF
library(ranger) # to train Balanced RF/ speed and efficiency
library(caret)  # to use train() for CV and Tuning
library(pROC) # for ROC(AUC) plot and calculation
```


```{r}
# Step 3: Model Development 
# Balanced Random Forest (BRF) using the cleaned imbalanced training set
# Load important libraries
# Extracting the majority and minority target class
majority_0 <- train_Fcleaned[train_Fcleaned$CHDRisk == 0,]
minority_1 <- train_Fcleaned[train_Fcleaned$CHDRisk == 1,]

# Generate samples (by under sampling of the majority class, hence, each tree will get a balanced data set)
set.seed(123) # ensures reproducibility
majority_sample1 <- majority_0[sample(nrow(majority_0), nrow(minority_1)),]
train_BALANCEDRF <- rbind(minority_1, majority_sample1) # combine the sampled majority class with minority class
predictor_f <- 14 # number of predictors (features)
m = round(sqrt(predictor_f)) # matry will take the sqrt of number of predictors

# Train balanced random forest 
BRF_model <- ranger(CHDRisk ~ ., data = train_BALANCEDRF, num.trees = 500, 
                      mtry = m,
                      probability = TRUE, 
                      importance = "impurity", 
                      classification = TRUE,   seed = 123)

print(BRF_model)

```

```{r}
# Predict using imbalanced validation set and evaluate the model's predictive performance
# Focus is on Recall(sensitivity) and ROC(AUC) true positive as predicting CHDRisk (1) accurately is the goal
predict_BRF <- predict(BRF_model, data = valid_Fcleaned)$predictions[,"1"]
predict_BRF_class <- ifelse(predict_BRF >= 0.33, 1, 0) # adjust classification threshold
# Convert probability to factor
predict_BRF_class <- factor(predict_BRF_class, levels = c(0,1))
# Print confusion matrix 
confusionMatrix(predict_BRF_class, valid_Fcleaned$CHDRisk, positive = "1")
# Compute ROC(AUC) Area Under the Curve
probs_BRF <- predict_BRF
rocob_BRF <- roc(valid_Fcleaned$CHDRisk, probs_BRF)
auc(rocob_BRF)
```

```{r}
# Apply Cross Validation(CV) and Hyperparameter Tuning (HT) to find the best parameters
# Set CV values
CV_values <- trainControl(method = "cv", number = 5)
# Set HT grid 
HT_grid <- expand.grid(mtry = c(2, 4, 6, m),
min.node.size = c(1,5,10), splitrule = "gini")

# Tune the model using train to find the best hyperparameters 
tune_BRF_model <- train(CHDRisk ~ ., data = train_BALANCEDRF,
                        method = "ranger", trControl = CV_values, # CV values is passed
                        tuneGrid = HT_grid, # HT grid is passed
                        importance = "impurity")

# View best hyperparameters identified
print(tune_BRF_model$bestTune)

```
```{r}
# Extract the best hyperparameters and keep them on a variable 
best1_mtry <- tune_BRF_model$bestTune$mtry
best1_minnz <- tune_BRF_model$bestTune$min.node.size
best1_splitrule <- tune_BRF_model$bestTune$splitrule
# Print the best hyperparameters
print(best1_mtry)
print(best1_minnz)
print(best1_splitrule)

```

```{r}
# Retrain the model using the identified best hyperparameters
final_BRF_model <- ranger(CHDRisk ~ ., data = train_BALANCEDRF, num.trees = 500, 
                      mtry = best1_mtry, # number of features randomly selected at each split
                      min.node.size = best1_minnz, # minimum number of samples in a terinal node
                      splitrule = best1_splitrule, # used to chose the best split (default Gini Impurity)
                      probability = TRUE, # output class probabilities
                      importance = "impurity", # feature contribution for split impurity 
                      classification = TRUE,   # tells it is a classification task (not regression)
                      seed = 123)

print(final_BRF_model)

```

```{r}
# Evaluate tunned and retrained model again using the validation set
pred_tune_BRF <- predict(final_BRF_model, data = valid_Fcleaned)$predictions[,"1"]
pred_tune_BRF_class <- ifelse(pred_tune_BRF >= 0.33, 1, 0) # adjust classification threshold
# Convert probability to factor
pred_tune_BRF_class <- factor(pred_tune_BRF_class, levels = c(0,1))
# Print confusion matrix 
confusionMatrix(pred_tune_BRF_class, valid_Fcleaned$CHDRisk, positive = "1")
# Compute ROC(AUC) Area Under the Curve
probs_BRF_tune <- pred_tune_BRF
rocob_BRF_tune <- roc(valid_Fcleaned$CHDRisk, probs_BRF_tune)
auc(rocob_BRF_tune)

```

# Measure Feature Importance
```{r}
# Model again to identify feature importance on predcition perfromance 
final_BRF_model2 <- ranger(CHDRisk ~ ., data = train_BALANCEDRF, num.trees = 500, 
                      mtry = best1_mtry, 
                      min.node.size = best1_minnz,
                      splitrule = best1_splitrule,
                      probability = TRUE, 
                      importance = "permutation", # impact of features on model prediction performance 
                      classification = TRUE,   seed = 123)

```


```{r}
# compute feature importance scores
# Importance for split impurity (impurity)
importance_scores1 <- final_BRF_model$variable.importance
print(sort(sorted_importance1, decreasing = TRUE))
cat("\n") # adds space between outputs
# Importance for model prediction performance (permutation)
importance_scores2 <- final_BRF_model2$variable.importance
print(sort(importance_scores2, decreasing = TRUE))
```

```{r}
# Plot the feature importance 
# Bar plot helps to visualize each predictors influence to reduce node impurity
par(mar = c(5,10,4,2) + 0.1)
barplot(sort(importance_scores1, decreasing = FALSE),
        main = "Features Relative Importance on Reducing Node Impurity",
        xlab = "Mean Decrease in Gini Index",
        horiz = TRUE,
        col = "skyblue",
        las = 1,
        cex.names = 0.8)

# Bar plot helps to visualize the feature importance on model prediction accuracy
par(mar = c(5,10,4,2) + 0.1)
barplot(sort(importance_scores2, decreasing = FALSE),
        main = "Features Relative Importance on Prediction Accuracy",
        xlab = "Mean Decrease Accuracy",
        horiz = TRUE,
        col = "brown",
        las = 1,
        cex.names = 0.8)

```

# Logistic Regression (LR)
```{r}
# Pre-process to rearrange data type of features for LR and SVM models
# Change factor features into numeric for validation set 
valid_FADASYN <- valid_Fcleaned # keep copy of the cleaned validation set
valid_FADASYN <- valid_FADASYN %>%
  mutate(across(where(is.factor), ~ as.numeric(as.character(.))))
valid_FADASYN$CHDRisk <- as.factor(valid_FADASYN$CHDRisk) # keep the target(CHDRisk) as factor

# Change factor features into numeric for testing set 
test_FADASYN <- test_Fcleaned # keep copy of the cleaned testing set
test_FADASYN <- test_FADASYN %>%
  mutate(across(where(is.factor), ~ as.numeric(as.character(.))))
test_FADASYN$CHDRisk <- as.factor(test_FADASYN$CHDRisk) # keep the target(CHDRisk) as factor

```


```{r}
# Load important libraries for Logistic Regression
library(glmnet) # for cross validation and hyperparameter tuning
library(caret) # for basic logistic regression training
library(pROC) # for ROC(AUC) plot and calculation

```



```{r}
# Train Logistic Regression (LR) using the balanced(FADASYN) data 
LR_model1 <- glm(CHDRisk ~ ., data = train_FADASYN, family = "binomial")
summary(LR_model1)

```

```{r}
# Evaluate model using validation set
# Predict probabilities using the trained LR_model1 
LR_probs1 <- predict(LR_model1, newdata = valid_FADASYN, type = "response")
# Convert probs to class labels 
LR_preds1 <- ifelse(LR_probs1 >= 0.5, "1", "0") # adjust classification threshold
# Make sure target var(CHDRisk) is factor with similar level
target_levels1 <- as.factor(valid_FADASYN$CHDRisk)
LR_preds1 <- factor(LR_preds1, levels = levels(target_levels1))
# Compute confusion matrix
confusionMatrix(LR_preds1, target_levels1, positive = "1")
# ROC(AUC) calculated 
roc_LR1 <- roc(valid_FADASYN$CHDRisk, LR_probs1)
auc(roc_LR1)

```

```{r}
# Cross Validation (CV) and Hyperparameter Tuning (HT) to improve model performance
# Split features and target(CHDRisk)
LR_feaures <- model.matrix(CHDRisk ~ ., data = train_FADASYN)[,-1] # extract features exclusing target
LR_target <- train_FADASYN$CHDRisk
# CV + HT
set.seed(123)
CV_LR <- cv.glmnet(
  LR_feaures, LR_target, alpha = 1, 
  family = "binomial", type.measure = "auc", nfolds = 5
)
# Extract best lambda from the CV + HT and use it to retrain model
best_LR_lambda <- CV_LR$lambda.min
# Print the best hyperparameter (lambda)
print(best_LR_lambda)
# Retrain model using best lambda
final_LRmodel <- glmnet(LR_feaures, LR_target, alpha = 1,
                      lambda = best_LR_lambda, family = "binomial")

```
```{r}
# Predict again using validation set to check performance improvement
# Prepare the validation set
val_features <- model.matrix(CHDRisk ~ ., data = valid_FADASYN)[,-1]
val_target <- valid_FADASYN$CHDRisk
# Predict probabilities
pred_Vprobs <- predict(final_LRmodel, newx = val_features, type = "response")
# Convert probs to class 
pred_Vclass <- ifelse(pred_Vprobs >= 0.5, 1, 0) # adjust classification threshold
pred_Vclass <- factor(pred_Vclass, levels = c("0", "1")) # Make it a factor
# Calculate and print the Confusion Matrix and statistics (Recall, Precision, and Balanced Accuracy)
confusionMatrix(pred_Vclass, val_target, positive= "1" )
# C alculate ROC(AUC)
roc_Vobj <- roc(val_target, as.numeric(pred_Vprobs))
auc(roc_Vobj)

```
# Measure Feature Importance (LR)
```{r}
# Extract coefficients of LR from the final retrained model
coefs_LR <- coef(final_LRmodel)
coefs_LR_df <- as.data.frame(as.matrix(coefs_LR)) # convert to data frame
coefs_LR_df$Feature <- rownames(coefs_LR_df)
colnames(coefs_LR_df)[1] <- "Coefficient"

# Remove intercept from the data frame 
coefs_LR_df <- coefs_LR_df[coefs_LR_df$Feature != "(Intercept)",]
# Compute importance 
coefs_LR_df$Importance <- abs(coefs_LR_df$Coefficient)

# Sort the data frame by importance (the most important ones on the top,with long bars)
coefs_LR_df <- coefs_LR_df[order(-coefs_LR_df$Importance),]
# Print the feature importance data frame
coefs_LR_df

# Plot feature importance 
ggplot(coefs_LR_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "brown") +
  coord_flip() + # flips vertical bars to horizontal (vertical(y) becomes horizontal)
  labs(title = "Feature Importance (Logistic Regression)", 
       x = "Feature", y = "Absolute Coefficient") +
  theme_minimal()
```

# Support Vector Machine (SVM) Model
```{r}
# Load important libraries 
library(e1071) # for svm method
library(caret) # for confusion matrix
library(kernlab) # for kernel based ML (SVM)

```


```{r}
# Train SVM Linear model using the balanced (train_FADASYN) data
SVM_Lmodel1 <- svm(CHDRisk ~ ., data = train_FADASYN, kernel = "linear",
                  scale = TRUE, probability = TRUE)
print(SVM_Lmodel1)

```

```{r}
# Predict and evaluate the SVM linear model using the validation set (valid_FADASYN)
pred_SVML1 <- attr(predict(SVM_Lmodel1, valid_FADASYN, probability = TRUE), "probabilities") [,"1"]
# Probability class assigned 
prob_SVM_class1 <- ifelse(pred_SVML1 >= 0.3, 1, 0) # adjust classification threshold
# Change probability class into factor
prob_SVM_class1 <- factor(prob_SVM_class1, levels = c("0", "1"))
# Generate a Confusion Matrix 
confusionMatrix(prob_SVM_class1, valid_FADASYN$CHDRisk, positive = "1")
# ROC(AUC) 
roc_SVML1 <- roc(valid_FADASYN$CHDRisk, pred_SVML1)
auc(roc_SVML1)

```

```{r}
# Cross Validation (CV) and Hyperparameter Tuning(HT)
# Tune to find optimal hyperparameter C for linear kernel based SVM
# Set seed for consistent reproducibility  
# 10 fold cross validation is implemented automatically 
set.seed(123)
tune_LSVM <- tune(svm, CHDRisk ~ ., data = train_FADASYN,
                   kernel = "linear",
                   ranges = list(cost = c(0.01, 1, 100)),
                   scale = TRUE
                   )
summary(tune_LSVM) # summary of the hyperparameter tuning process
tune_LSVM$best.parameters$cost # extract the best cost value from the model
optimal_SVM_cost <- tune_LSVM$best.parameters$cost # keep the optimal cost on a variable to be used later 

```
```{r}
# Retrain the final SVM classifier model using linear kernel and optimal value of hyperparameter C
final_LSVM_model <- svm(CHDRisk ~ ., data = train_FADASYN,
                 kernel = "linear",
                 cost = optimal_SVM_cost, # optimal cost assigned to cost value during training 
                 scale = TRUE,
                 probability = TRUE  # set to be used for the ROC curve
                 ) 
summary(final_LSVM_model)

```

```{r}
# Predict and evaluate the final linear SVM  model using the validation set (valid_FADASYN)
pred_SVML2 <- attr(predict(final_LSVM_model, valid_FADASYN, probability = TRUE), "probabilities") [,"1"]
# Probability class assigned 
prob_SVM_class2 <- ifelse(pred_SVML2 >= 0.3, 1, 0) # adjust classification threshold
# Change probability class into factor
prob_SVM_class2 <- factor(prob_SVM_class2, levels = c("0", "1"))
# Generate a Confusion Matrix 
confusionMatrix(prob_SVM_class2, valid_FADASYN$CHDRisk, positive = "1")
# ROC(AUC) Area under the curve value 
roc_SVML2 <- roc(valid_FADASYN$CHDRisk, pred_SVML2)
auc(roc_SVML2)

```
# Feature Importance (Linear SVM model)
```{r}
# The linear SVM model Feature Importance
# Extract coefficient's weight from the model
coefs_weights <- t(final_LSVM_model$coefs) %*% final_LSVM_model$SV
# Convert to vector 
feature_impo <- abs(as.vector(coefs_weights)) # abs ( all positive values)
names(feature_impo) <- colnames(train_FADASYN)[colnames(train_FADASYN) != "CHDRisk"]
# Sort the feature importance in decreasing order(the higher values on the top)
feature_impo <- sort(feature_impo, decreasing = TRUE)
print(feature_impo)

```

```{r}
# Plot the feature importance using ggplot
# Create a data frame to store the importance
df__importance <- data.frame(Feature_name = names(feature_impo),
                            Importance_val = as.numeric(feature_impo))
# Rearrange the data frame in decreasing importance and convert it into factor level
df__importance$Feature_name <- factor(df__importance$Feature_name, 
                                 levels = rev(names(sort(feature_impo, decreasing = TRUE))))

# Plot feature importance 
ggplot(df__importance, aes(x = Feature_name, y = Importance_val)) +
  geom_bar(stat = "identity", fill = "brown") +
  coord_flip() +
  labs(title = "SVM (Linear Kernel) Feature Importance", 
       x = "Feature", y = "Importance") +
  theme_minimal()

```






```{r}
# End of page
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
